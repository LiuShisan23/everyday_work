# 2024/3/19

学习thorough-pytorch的第六章以及第四章的实战部分。着重点在于数据的读取，和微调是如何进行的。

单卡/多卡保存+单卡/多卡加载，可以实践一下，在autodl上面。

开始进攻bert和lora。最近datawhale发布了关于LLM微调的一个项目，可以在autodl上面下手，可以了解一下。关于finetuning的项目和bert+lora一起入手了解finetuning。

map函数有点忘了

distilbert: https://medium.com/@simon.gsponer/a-comprehensive-guide-using-a-bert-llm-on-texts-exceeding-the-maximum-input-size-47d1b72e397f

我觉得这个项目的微调仅仅是，设置了一个滑动窗口，从而可以训练所有的数据。多了一个参数stride，input可以超出限制。

datacollator: https://lowin.li/2021/09/25/transformers-yi-datacollator/

bert+lora: https://medium.com/@simon.gsponer/a-comprehensive-guide-ii-finetuning-a-bert-llm-with-lora-and-make-it-pipeline-compatible-9508e3822907

bert的源码讲解：https://zhuanlan.zhihu.com/p/398418375