# 2024/3/18

今天把个人陈述写完发给留学机构。（还没写完）

热血沸腾了hh看完这篇文章。https://www.zhihu.com/question/477552623/answer/2056711175

运行bert

看到一篇datawhale新出的关于微调LLM的github，可以借此机会运行一下。

因为关于模型保存和修改以及读取，是基于resnet-50，所以借机温习一下resnet。

> 卷积过程中关于通道数的问题https://zhuanlan.zhihu.com/p/251068800

> 1*1卷积核的作用https://blog.csdn.net/qq_41554005/article/details/107392995

搞明白了resnet中的downsample用1x1的卷积和来实现提升维度实现skip-connection

关于nn.modulelist和nn.sequential https://huaweicloud.csdn.net/6380694fdacf622b8df870f2.html?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-1-112618607-blog-82980222.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-1-112618607-blog-82980222.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=2

torch.cat https://blog.csdn.net/qian2213762498/article/details/88795848

torch.unsqueeze与squeezehttps://zhuanlan.zhihu.com/p/86763381

> 对于unsqueeze操作可以复习下thoriugh-pytorch中2.1节的内容和配套代码。

